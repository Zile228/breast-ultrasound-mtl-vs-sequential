{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-27T18:34:04.036805Z",
     "iopub.status.busy": "2025-07-27T18:34:04.036533Z",
     "iopub.status.idle": "2025-07-27T18:35:27.230500Z",
     "shell.execute_reply": "2025-07-27T18:35:27.229759Z",
     "shell.execute_reply.started": "2025-07-27T18:34:04.036778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio timm thop torchmetrics tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:27.232620Z",
     "iopub.status.busy": "2025-07-27T18:35:27.232365Z",
     "iopub.status.idle": "2025-07-27T18:35:48.673859Z",
     "shell.execute_reply": "2025-07-27T18:35:48.673195Z",
     "shell.execute_reply.started": "2025-07-27T18:35:27.232596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import numbers\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torchvision.ops import DeformConv2d\n",
    "import matplotlib.pyplot as plt\n",
    "import timm # PyTorch Image Models\n",
    "from thop import profile # Tính FLOPs và Params\n",
    "import pandas as pd \n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "from torchmetrics import JaccardIndex\n",
    "from tqdm import tqdm\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.675224Z",
     "iopub.status.busy": "2025-07-27T18:35:48.674639Z",
     "iopub.status.idle": "2025-07-27T18:35:48.684136Z",
     "shell.execute_reply": "2025-07-27T18:35:48.683260Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.675193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 0. TIỆN ÍCH VÀ HÀM HỖ TRỢ\n",
    "def set_seed(seed):\n",
    "    \"\"\"Cố định seed cho các thư viện để đảm bảo kết quả có thể tái lập.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Dừng quá trình huấn luyện sớm nếu metric không cải thiện sau một số epoch nhất định.\"\"\"\n",
    "    def __init__(self, patience=10, delta=0.001, verbose=True, mode='max', path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Số epoch chờ đợi sau khi metric ngừng cải thiện.\n",
    "            delta (float): Mức thay đổi tối thiểu được coi là một sự cải thiện.\n",
    "            verbose (bool): Nếu True, in thông báo mỗi khi metric cải thiện.\n",
    "            mode (str): 'min' cho loss, 'max' cho accuracy/dice.\n",
    "            path (str): Đường dẫn lưu checkpoint của model tốt nhất.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.mode = mode\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_metric_min = np.Inf\n",
    "\n",
    "        if self.mode == 'max':\n",
    "            self.delta *= 1\n",
    "        else: # min\n",
    "            self.delta *= -1\n",
    "\n",
    "    def __call__(self, val_metric, model):\n",
    "        score = val_metric\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_metric, model)\n",
    "        elif (score - self.best_score) < self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} / {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_metric, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_metric, model):\n",
    "        \"\"\"Lưu model khi metric được cải thiện.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f'Validation metric improved ({self.val_metric_min:.4f} --> {val_metric:.4f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_metric_min = val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.685184Z",
     "iopub.status.busy": "2025-07-27T18:35:48.684916Z",
     "iopub.status.idle": "2025-07-27T18:35:48.800785Z",
     "shell.execute_reply": "2025-07-27T18:35:48.799953Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.685156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # --- Data & Path ---\n",
    "    DATASET_PATH = '/kaggle/input/dataset-busi/Dataset_BUSI_with_GT'\n",
    "    OUTPUT_MASK_DIR = 'merged_masks'\n",
    "    CLASS_JSON_PATH = 'class_indices.json'\n",
    "    MTL_MODEL_CHECKPOINT_PATH = 'best_model.pt'\n",
    "    SEG_MODEL_CHECKPOINT_PATH = 'best_seg_model.pt'\n",
    "    CLS_MODEL_CHECKPOINT_PATH = 'best_cls_model.pt'\n",
    "\n",
    "    # --- Model Architecture ---\n",
    "    # Lựa chọn: 'multitask', 'sequential' \n",
    "    MODEL_TYPE = 'sequential' \n",
    "    BACKBONE = 'efficientnet_b4'\n",
    "    NUM_CLASSES = 3 # benign, malignant, normal\n",
    "    USE_Deform = True  # True: Dùng Deformable Convolution Block, False: không dùng\n",
    "    # Lựa chọn classification head: 'capsnet' hoặc 'fc' (Fully Connected)\n",
    "    CLASSIFICATION_HEAD = 'capsnet' \n",
    "    \n",
    "    # --- Training Parameters ---\n",
    "    IMG_SIZE = 256\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 100\n",
    "    LEARNING_RATE = 2e-4\n",
    "    TEST_RATIO = 0.2\n",
    "    LR_SCHEDULER = 'plateau' # Lựa chọn: 'plateau', 'cosine'\n",
    "    EARLY_STOPPING_PATIENCE = 20\n",
    "    EARLY_STOPPING_DELTA = 0.001 # Thay đổi tối thiểu để coi là cải thiện (cho Dice score)\n",
    "    \n",
    "    #--- Ablation Study & Reproducibility ---\n",
    "    SEED = 42\n",
    "    NUM_RUNS = 30 # Số lần chạy lại toàn bộ thử nghiệm\n",
    "    \n",
    "    # --- Implementation Helper ---\n",
    "    # True: Chạy thử để debug, False: Chạy trên toàn bộ dataset\n",
    "    TEST_IMPLEMENTATION = False\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Khởi tạo config\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.803644Z",
     "iopub.status.busy": "2025-07-27T18:35:48.803316Z",
     "iopub.status.idle": "2025-07-27T18:35:48.830437Z",
     "shell.execute_reply": "2025-07-27T18:35:48.829643Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.803614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PHẦN I: CÁC HÀM XỬ LÝ DATASET\n",
    "# --- 1. HÀM TẠO DATASET GỐC ---\n",
    "def make_dataset(root, output_mask_dir='merged_masks'):\n",
    "    \"\"\"\n",
    "    Tạo dataset từ thư mục, gộp các mask và trả về danh sách các đường dẫn đầy đủ.\n",
    "\n",
    "    Args:\n",
    "        root (str): Đường dẫn đến thư mục gốc chứa các thư mục con (mỗi thư mục là một lớp).\n",
    "        output_mask_dir (str, optional): Thư mục lưu các ảnh mask đã gộp.\n",
    "\n",
    "    Returns:\n",
    "        list of tuple: Danh sách các mẫu dữ liệu, mỗi phần tử là một tuple:\n",
    "                       (đường dẫn ảnh gốc, đường dẫn ảnh mask, nhãn dạng số nguyên).\n",
    "    \"\"\"\n",
    "    img_class_names = [cls for cls in os.listdir(root) if os.path.isdir(os.path.join(root, cls))]\n",
    "    img_class_names.sort()\n",
    "    class_to_idx = {name: i for i, name in enumerate(img_class_names)}\n",
    "\n",
    "    with open(config.CLASS_JSON_PATH, 'w') as json_file:\n",
    "        json.dump(class_to_idx, json_file, indent=4)\n",
    "\n",
    "    dataset_items = []\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "\n",
    "    for class_name, label in class_to_idx.items():\n",
    "        class_dir = os.path.join(root, class_name)\n",
    "        original_images = [fname for fname in os.listdir(class_dir) if '_mask' not in fname and fname.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        for img_name in original_images:\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            base_name = os.path.splitext(img_name)[0]\n",
    "            gt_files = [gt for gt in os.listdir(class_dir) if gt.startswith(base_name + '_mask')]\n",
    "            \n",
    "            if not gt_files:\n",
    "                continue\n",
    "\n",
    "            if len(gt_files) > 1:\n",
    "                merged_mask = None\n",
    "                for gt_file in gt_files:\n",
    "                    mask_path = os.path.join(class_dir, gt_file)\n",
    "                    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    if merged_mask is None:\n",
    "                        merged_mask = mask\n",
    "                    else:\n",
    "                        merged_mask = cv2.bitwise_or(merged_mask, mask)\n",
    "                \n",
    "                merged_mask_name = f\"{base_name}_mask_merged.png\"\n",
    "                merged_mask_path = os.path.join(output_mask_dir, merged_mask_name)\n",
    "                cv2.imwrite(merged_mask_path, merged_mask)\n",
    "                dataset_items.append((img_path, merged_mask_path, label))\n",
    "            else:\n",
    "                mask_path = os.path.join(class_dir, gt_files[0])\n",
    "                dataset_items.append((img_path, mask_path, label))\n",
    "    return dataset_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.831762Z",
     "iopub.status.busy": "2025-07-27T18:35:48.831440Z",
     "iopub.status.idle": "2025-07-27T18:35:48.857621Z",
     "shell.execute_reply": "2025-07-27T18:35:48.857082Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.831711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 2. CÁC LỚP BIẾN ĐỔI DỮ LIỆU (AUGMENTATION) ---\n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "    def __call__(self, img, mask):\n",
    "        for t in self.transforms:\n",
    "            img, mask = t(img, mask)\n",
    "        return img, mask\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = (int(size), int(size)) if isinstance(size, numbers.Number) else size\n",
    "    def __call__(self, img, mask):\n",
    "        return (cv2.resize(img, self.size, interpolation=cv2.INTER_LINEAR),\n",
    "                cv2.resize(mask, self.size, interpolation=cv2.INTER_NEAREST))\n",
    "\n",
    "class RandomHorizontallyFlip(object):\n",
    "    def __init__(self, p=0.5): self.p = p\n",
    "    def __call__(self, img, mask):\n",
    "        return (cv2.flip(img, 1), cv2.flip(mask, 1)) if random.random() < self.p else (img, mask)\n",
    "\n",
    "class RandomVerticallyFlip(object):\n",
    "    def __init__(self, p=0.5): self.p = p\n",
    "    def __call__(self, img, mask):\n",
    "        return (cv2.flip(img, 0), cv2.flip(mask, 0)) if random.random() < self.p else (img, mask)\n",
    "\n",
    "class RandomRotate(object):\n",
    "    def __init__(self, degree): self.degree = degree\n",
    "    def __call__(self, img, mask):\n",
    "        rotate_degree = random.uniform(-self.degree, self.degree)\n",
    "        h, w = img.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, rotate_degree, 1.0)\n",
    "        img_rotated = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR, borderValue=0)\n",
    "        mask_rotated = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderValue=0)\n",
    "        return img_rotated, mask_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.858701Z",
     "iopub.status.busy": "2025-07-27T18:35:48.858443Z",
     "iopub.status.idle": "2025-07-27T18:35:48.883392Z",
     "shell.execute_reply": "2025-07-27T18:35:48.882695Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.858672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 3. DATASET CLASS ---\n",
    "class BUSIDataset(data.Dataset):\n",
    "    def __init__(self, dataset_items, joint_transform=None, image_transform=None, mask_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_items (list): Danh sách từ hàm make_dataset.\n",
    "            joint_transform (callable, optional): Transform áp dụng đồng thời cho cả ảnh và mask.\n",
    "            image_transform (callable, optional): Transform chỉ áp dụng cho ảnh (sau joint_transform).\n",
    "            mask_transform (callable, optional): Transform chỉ áp dụng cho mask (sau joint_transform).\n",
    "        \"\"\"\n",
    "        self.items = dataset_items\n",
    "        self.joint_transform = joint_transform\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, mask_path, label = self.items[index]\n",
    "\n",
    "        # Đọc ảnh và mask bằng cv2\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Chuyển từ BGR (cv2) sang RGB\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Áp dụng các phép biến đổi hình học (augmentation)\n",
    "        if self.joint_transform is not None:\n",
    "            img, mask = self.joint_transform(img, mask)\n",
    "\n",
    "        # Áp dụng các phép biến đổi riêng lẻ (normalize, to_tensor)\n",
    "        if self.image_transform is not None:\n",
    "            img = self.image_transform(img)\n",
    "        \n",
    "        if self.mask_transform is not None:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        return img, mask, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "class ClassificationSequentialDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset cho giai đoạn 2 của mô hình Sequential.\n",
    "    Nó nhận vào một mô hình segmentation đã được huấn luyện để tạo ra predicted mask.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_items, seg_model, size, image_transform=None):\n",
    "        self.items = dataset_items\n",
    "        self.seg_model = seg_model\n",
    "        self.size = size\n",
    "        self.image_transform = image_transform\n",
    "        self.seg_model.eval() # Luôn đặt seg_model ở chế độ eval\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, _, label = self.items[index] # Không cần mask_path gốc nữa\n",
    "\n",
    "        # 1. Đọc và chuẩn bị ảnh gốc\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (self.size, self.size), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Áp dụng transform cho ảnh gốc để đưa vào seg_model\n",
    "        # Lưu ý: không dùng augmentation hình học ở đây để đảm bảo sự ổn định\n",
    "        if self.image_transform:\n",
    "            img_tensor = self.image_transform(img)\n",
    "\n",
    "        # 2. Tạo predicted mask từ seg_model\n",
    "        with torch.no_grad():\n",
    "            # Thêm chiều batch và chuyển đến device\n",
    "            img_tensor = img_tensor.unsqueeze(0).to(config.DEVICE)\n",
    "            predicted_mask = self.seg_model(img_tensor)\n",
    "            \n",
    "            # Bỏ chiều batch và chuyển về CPU, binarize mask\n",
    "            predicted_mask = (predicted_mask.squeeze(0) > 0.5).float()\n",
    "\n",
    "        # 3. Trả về predicted_mask và label\n",
    "        return predicted_mask, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.884993Z",
     "iopub.status.busy": "2025-07-27T18:35:48.884384Z",
     "iopub.status.idle": "2025-07-27T18:35:48.903557Z",
     "shell.execute_reply": "2025-07-27T18:35:48.902750Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.884961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 4. HÀM TIỆN ÍCH: TÍNH MEAN VÀ STD ---\n",
    "def calculate_mean_std(dataset):\n",
    "    \"\"\"Tính toán mean và std của tập dữ liệu hình ảnh.\"\"\"\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=10, num_workers=0, shuffle=False)\n",
    "    \n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    \n",
    "    print(\"Bắt đầu tính toán mean và std của tập train...\")\n",
    "    for images, _, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += batch_samples\n",
    "\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    \n",
    "    print(f\"Tính toán xong!\")\n",
    "    return mean.tolist(), std.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.904840Z",
     "iopub.status.busy": "2025-07-27T18:35:48.904494Z",
     "iopub.status.idle": "2025-07-27T18:35:48.929002Z",
     "shell.execute_reply": "2025-07-27T18:35:48.928133Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.904792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PHẦN II: CÁC KHỐI KIẾN TRÚC (ATTENTION, CAPSULE NETWORK)\n",
    "\n",
    "def squash(vectors, dim=-1):\n",
    "    s_squared_norm = (vectors ** 2).sum(dim=dim, keepdim=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / torch.sqrt(s_squared_norm + 1e-8)\n",
    "    return scale * vectors\n",
    "\n",
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, num_route_nodes, in_channels, out_channels,\n",
    "                 kernel_size=None, stride=None, num_iterations=3):\n",
    "        super().__init__()\n",
    "        self.num_route_nodes = num_route_nodes\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        if num_route_nodes != -1:  # DigitCaps\n",
    "            # Trọng số cho routing, shape (num_capsules, num_route_nodes, in_channels, out_channels)\n",
    "            self.route_weights = nn.Parameter(\n",
    "                torch.randn(num_capsules, num_route_nodes, in_channels, out_channels)\n",
    "            )\n",
    "        else:  # PrimaryCaps\n",
    "            self.capsules = nn.ModuleList([\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0\n",
    "                ) for _ in range(num_capsules)\n",
    "            ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_route_nodes != -1: # DigitCaps\n",
    "            # Input x shape: (batch_size, num_route_nodes, in_channels)\n",
    "            \n",
    "            # Sử dụng einsum để tính toán các vector dự đoán (priors) một cách an toàn và rõ ràng\n",
    "            # 'bni,cnio->bcno' -> priors shape: (batch_size, num_capsules, num_route_nodes, out_channels)\n",
    "            priors = torch.einsum('bni,cnio->bcno', x, self.route_weights)\n",
    "            \n",
    "            # Khởi tạo logits với shape (batch_size, num_capsules, num_route_nodes)\n",
    "            logits = torch.zeros(*priors.shape[:3], device=x.device)\n",
    "\n",
    "            for i in range(self.num_iterations):\n",
    "                # Softmax trên num_route_nodes (dim=2)\n",
    "                probs = F.softmax(logits, dim=2) \n",
    "                \n",
    "                # Tính tổng có trọng số của các priors để có được vector đầu ra\n",
    "                # (b,c,n,1) * (b,c,n,o) -> sum(dim=2) -> (b,c,o)\n",
    "                outputs = squash((probs.unsqueeze(-1) * priors).sum(dim=2))\n",
    "                \n",
    "                if i < self.num_iterations - 1:\n",
    "                    # Cập nhật logits bằng \"agreement\"\n",
    "                    # (b,c,n,o) * (b,c,1,o) -> sum(dim=-1) -> (b,c,n)\n",
    "                    delta = (priors * outputs.unsqueeze(2)).sum(dim=-1)\n",
    "                    logits = logits + delta\n",
    "                    \n",
    "            return outputs # Shape: (batch_size, num_capsules, out_channels)\n",
    "        \n",
    "        else: # PrimaryCaps\n",
    "            # Input x shape: (batch_size, in_channels, height, width)\n",
    "            outputs = [capsule(x) for capsule in self.capsules]\n",
    "            outputs = torch.stack(outputs, dim=1)\n",
    "            batch, n_caps, o_ch, h, w = outputs.size()\n",
    "            \n",
    "            # Reshape để có được danh sách các capsules\n",
    "            # (batch_size, num_capsules, out_channels, h*w) -> (batch_size, h*w, num_capsules, out_channels)\n",
    "            outputs = outputs.view(batch, n_caps, o_ch, -1).permute(0, 3, 1, 2)\n",
    "            # (batch_size, h*w*num_capsules, out_channels)\n",
    "            outputs = outputs.reshape(batch, -1, o_ch)\n",
    "            return squash(outputs)\n",
    "\n",
    "class CapsuleNetwork(nn.Module):\n",
    "    def __init__(self, in_channels, in_hw, num_classes):\n",
    "        super().__init__()\n",
    "        self.in_hw = in_hw\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.primary_caps = CapsuleLayer(\n",
    "            num_capsules=8,\n",
    "            num_route_nodes=-1,\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            stride=3\n",
    "        )\n",
    "\n",
    "        kernel, stride = 3, 3\n",
    "        primary_caps_out_hw = (self.in_hw - kernel) // stride + 1\n",
    "        num_route_nodes = 8 * primary_caps_out_hw * primary_caps_out_hw\n",
    "\n",
    "        self.digit_caps = CapsuleLayer(\n",
    "            num_capsules=self.num_classes,\n",
    "            num_route_nodes=num_route_nodes,\n",
    "            in_channels=16, # out_channels của primary_caps\n",
    "            out_channels=8\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        primary_output = self.primary_caps(x)\n",
    "        digit_output = self.digit_caps(primary_output)\n",
    "        v_length = torch.norm(digit_output, dim=-1)\n",
    "        return v_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.930161Z",
     "iopub.status.busy": "2025-07-27T18:35:48.929900Z",
     "iopub.status.idle": "2025-07-27T18:35:48.949361Z",
     "shell.execute_reply": "2025-07-27T18:35:48.948782Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.930114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DeformableConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Khối Deformable Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, stride=1):\n",
    "        super(DeformableConvBlock, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        # Conv layer để sinh ra offset\n",
    "        self.offset_conv = nn.Conv2d(in_channels, 2 * kernel_size * kernel_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        # Deformable Convolution layer\n",
    "        self.dcn = DeformConv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        offset = self.offset_conv(x)\n",
    "        x = self.dcn(x, offset)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Khối Convolution tiêu chuẩn.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.950490Z",
     "iopub.status.busy": "2025-07-27T18:35:48.950228Z",
     "iopub.status.idle": "2025-07-27T18:35:48.983066Z",
     "shell.execute_reply": "2025-07-27T18:35:48.982448Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.950461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# PHẦN III-A: KIẾN TRÚC CHO MULTITASK MODEL\n",
    "# =================================================================================\n",
    "class UNet_MTL(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(UNet_MTL, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.backbone = timm.create_model(cfg.BACKBONE, pretrained=True, features_only=True)\n",
    "        \n",
    "        backbone_channels = self.backbone.feature_info.channels()\n",
    "        # efficientnet_b4 channels: [24, 32, 56, 160, 448]\n",
    "        \n",
    "        conv_block = DeformableConvBlock if cfg.USE_Deform else ConvBlock\n",
    "\n",
    "        # Số kênh đầu vào = kênh từ upsampling + kênh từ skip connection\n",
    "        self.upconv4 = nn.ConvTranspose2d(backbone_channels[4], backbone_channels[3], kernel_size=2, stride=2)\n",
    "        self.dec4 = conv_block(backbone_channels[3] + backbone_channels[3], backbone_channels[3])\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(backbone_channels[3], backbone_channels[2], kernel_size=2, stride=2)\n",
    "        self.dec3 = conv_block(backbone_channels[2] + backbone_channels[2], backbone_channels[2])\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(backbone_channels[2], backbone_channels[1], kernel_size=2, stride=2)\n",
    "        self.dec2 = conv_block(backbone_channels[1] + backbone_channels[1], backbone_channels[1])\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(backbone_channels[1], backbone_channels[0], kernel_size=2, stride=2)\n",
    "        self.dec1 = conv_block(backbone_channels[0] + backbone_channels[0], backbone_channels[0])\n",
    "\n",
    "        # --- Heads ---\n",
    "        # 1. Segmentation Head\n",
    "        self.seg_head = nn.Conv2d(backbone_channels[0], 1, kernel_size=1)\n",
    "\n",
    "        # 2. Classification Head\n",
    "        if cfg.CLASSIFICATION_HEAD == 'capsnet':\n",
    "            bottleneck_hw = cfg.IMG_SIZE // self.backbone.feature_info.reduction()[-1]\n",
    "            self.cls_head = CapsuleNetwork(\n",
    "                in_channels=backbone_channels[4], \n",
    "                in_hw=bottleneck_hw, \n",
    "                num_classes=cfg.NUM_CLASSES\n",
    "            )\n",
    "        else: # 'fc'\n",
    "            self.cls_head = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(backbone_channels[4], 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(512, cfg.NUM_CLASSES)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- Encoder ---\n",
    "        features = self.backbone(x)\n",
    "        enc1_out, enc2_out, enc3_out, enc4_out, bottleneck_out = features\n",
    "\n",
    "        # --- Classification Branch ---\n",
    "        cls_output = self.cls_head(bottleneck_out)\n",
    "        \n",
    "        # --- Decoder (Segmentation Branch) ---\n",
    "        d4 = self.upconv4(bottleneck_out)\n",
    "        d4 = torch.cat([d4, enc4_out], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        \n",
    "        d3 = self.upconv3(d4)\n",
    "        d3 = torch.cat([d3, enc3_out], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, enc2_out], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, enc1_out], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        # Phóng to feature map cuối cùng về đúng kích thước của ảnh đầu vào (x)\n",
    "        d1 = F.interpolate(d1, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Đầu ra segmentation thường dùng sigmoid để đưa giá trị về [0, 1]\n",
    "        seg_output = torch.sigmoid(self.seg_head(d1))\n",
    "        \n",
    "        return seg_output, cls_output\n",
    "\n",
    "# =================================================================================\n",
    "# PHẦN III-B: KIẾN TRÚC CHO SEQUENTIAL MODEL\n",
    "# =================================================================================\n",
    "\n",
    "class UNet_Segmentation(nn.Module):\n",
    "    \"\"\"\n",
    "    Kiến trúc U-Net chỉ cho tác vụ Segmentation.\n",
    "    Về cơ bản là UNet_MTL nhưng đã loại bỏ nhánh classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super(UNet_Segmentation, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.backbone = timm.create_model(cfg.BACKBONE, pretrained=True, features_only=True)\n",
    "        \n",
    "        backbone_channels = self.backbone.feature_info.channels()\n",
    "        conv_block = DeformableConvBlock if cfg.USE_Deform else ConvBlock\n",
    "\n",
    "        # Decoder Path\n",
    "        self.upconv4 = nn.ConvTranspose2d(backbone_channels[4], backbone_channels[3], kernel_size=2, stride=2)\n",
    "        self.dec4 = conv_block(backbone_channels[3] + backbone_channels[3], backbone_channels[3])\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(backbone_channels[3], backbone_channels[2], kernel_size=2, stride=2)\n",
    "        self.dec3 = conv_block(backbone_channels[2] + backbone_channels[2], backbone_channels[2])\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(backbone_channels[2], backbone_channels[1], kernel_size=2, stride=2)\n",
    "        self.dec2 = conv_block(backbone_channels[1] + backbone_channels[1], backbone_channels[1])\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(backbone_channels[1], backbone_channels[0], kernel_size=2, stride=2)\n",
    "        self.dec1 = conv_block(backbone_channels[0] + backbone_channels[0], backbone_channels[0])\n",
    "\n",
    "        # Segmentation Head\n",
    "        self.seg_head = nn.Conv2d(backbone_channels[0], 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        features = self.backbone(x)\n",
    "        enc1_out, enc2_out, enc3_out, enc4_out, bottleneck_out = features\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.upconv4(bottleneck_out)\n",
    "        d4 = torch.cat([d4, enc4_out], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        \n",
    "        d3 = self.upconv3(d4)\n",
    "        d3 = torch.cat([d3, enc3_out], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, enc2_out], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, enc1_out], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        d1 = F.interpolate(d1, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        seg_output = torch.sigmoid(self.seg_head(d1))\n",
    "        \n",
    "        return seg_output\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model phân loại nhận đầu vào là một ảnh mask (1 kênh).\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # Feature Extractor đơn giản cho ảnh mask\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 256 -> 128\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 128 -> 64\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 64 -> 32\n",
    "        )\n",
    "        \n",
    "        # Tái sử dụng Classification Head đã có\n",
    "        if cfg.CLASSIFICATION_HEAD == 'capsnet':\n",
    "            # Kích thước ảnh sau feature extractor: 32x32\n",
    "            # Số kênh cuối cùng: 64\n",
    "            self.cls_head = CapsuleNetwork(\n",
    "                in_channels=64,\n",
    "                in_hw=32, \n",
    "                num_classes=cfg.NUM_CLASSES\n",
    "            )\n",
    "        else: # 'fc'\n",
    "            self.cls_head = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(64, 128), # 64 là số kênh từ feature_extractor\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(128, cfg.NUM_CLASSES)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x là ảnh mask có shape (batch, 1, H, W)\n",
    "        features = self.feature_extractor(x)\n",
    "        cls_output = self.cls_head(features)\n",
    "        return cls_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:48.984105Z",
     "iopub.status.busy": "2025-07-27T18:35:48.983842Z",
     "iopub.status.idle": "2025-07-27T18:35:49.005604Z",
     "shell.execute_reply": "2025-07-27T18:35:49.005029Z",
     "shell.execute_reply.started": "2025-07-27T18:35:48.984076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PHẦN IV: LOSS FUNCTIONS\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.contiguous().view(-1)\n",
    "        target = target.contiguous().view(-1)\n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self, m_pos=0.9, m_neg=0.1, lambda_=0.5):\n",
    "        super(MarginLoss, self).__init__()\n",
    "        self.m_pos = m_pos\n",
    "        self.m_neg = m_neg\n",
    "        self.lambda_ = lambda_\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # y_true is class indices, y_pred is lengths of capsule vectors\n",
    "        y_true_one_hot = F.one_hot(y_true, num_classes=y_pred.size(1)).float()\n",
    "        \n",
    "        pos_loss = F.relu(self.m_pos - y_pred).pow(2)\n",
    "        neg_loss = F.relu(y_pred - self.m_neg).pow(2)\n",
    "        \n",
    "        loss = y_true_one_hot * pos_loss + self.lambda_ * (1 - y_true_one_hot) * neg_loss\n",
    "        return loss.sum(dim=1).mean()\n",
    "\n",
    "class UncertaintyWeightedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Hàm loss tự động cân bằng trọng số giữa 2 tác vụ dựa trên paper của Kendall et al. 2017)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tasks=2):\n",
    "        super(UncertaintyWeightedLoss, self).__init__()\n",
    "        # Learnable parameters cho mỗi task (log variance)\n",
    "        self.log_vars = nn.Parameter(torch.zeros(num_tasks))\n",
    "\n",
    "    def forward(self, loss_seg, loss_cls):\n",
    "        # Task 1: Segmentation\n",
    "        precision_seg = torch.exp(-self.log_vars[0])\n",
    "        weighted_loss_seg = precision_seg * loss_seg + self.log_vars[0]\n",
    "\n",
    "        # Task 2: Classification\n",
    "        precision_cls = torch.exp(-self.log_vars[1])\n",
    "        weighted_loss_cls = precision_cls * loss_cls + self.log_vars[1]\n",
    "        \n",
    "        # Trả về tổng loss và các loss riêng lẻ để theo dõi\n",
    "        return weighted_loss_seg + weighted_loss_cls, loss_seg, loss_cls, self.log_vars.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:49.006683Z",
     "iopub.status.busy": "2025-07-27T18:35:49.006454Z",
     "iopub.status.idle": "2025-07-27T18:35:49.038893Z",
     "shell.execute_reply": "2025-07-27T18:35:49.038111Z",
     "shell.execute_reply.started": "2025-07-27T18:35:49.006666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PHẦN V: TRAINING & EVALUATION LOOP\n",
    "\n",
    "# ==============================================================================\n",
    "# PHẦN V-A: HÀM TRAIN/EVAL CHO MÔ HÌNH MTL\n",
    "# ==============================================================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, seg_criterion, cls_criterion, uncertainty_loss, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    # Bọc loader bằng tqdm để tạo thanh tiến trình\n",
    "    # desc sẽ hiển thị mô tả cho thanh tiến trình\n",
    "    loader_tqdm = tqdm(loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    \n",
    "    total_loss, total_seg_loss, total_cls_loss = 0, 0, 0\n",
    "\n",
    "    for i, (imgs, masks, labels) in enumerate(loader_tqdm):\n",
    "        if config.TEST_IMPLEMENTATION and i >= 10:\n",
    "            break\n",
    "            \n",
    "        imgs = imgs.to(config.DEVICE)\n",
    "        masks = masks.to(config.DEVICE)\n",
    "        labels = labels.to(config.DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        seg_pred, cls_pred = model(imgs)\n",
    "        \n",
    "        loss_s = seg_criterion(seg_pred, masks)\n",
    "        loss_c = cls_criterion(cls_pred, labels)\n",
    "\n",
    "        combined_loss, _, _, _ = uncertainty_loss(loss_s, loss_c)\n",
    "        \n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Cập nhật các giá trị loss lên thanh tiến trình\n",
    "        loader_tqdm.set_postfix(loss=combined_loss.item(), seg_loss=loss_s.item(), cls_loss=loss_c.item())\n",
    "\n",
    "        total_loss += combined_loss.item()\n",
    "        total_seg_loss += loss_s.item()\n",
    "        total_cls_loss += loss_c.item()\n",
    "        \n",
    "    num_batches = 10 if config.TEST_IMPLEMENTATION else len(loader)\n",
    "    return total_loss / num_batches, total_seg_loss / num_batches, total_cls_loss / num_batches\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1.0  # Ngăn chia cho 0\n",
    "    # Chuyển thành tensor 1-D\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "\n",
    "def evaluate(model, loader, seg_criterion, cls_criterion, config):\n",
    "    model.eval()\n",
    "    \n",
    "    # Khởi tạo metrics từ torchmetrics\n",
    "    jaccard = JaccardIndex(task=\"binary\").to(config.DEVICE)\n",
    "    accuracy_metric = MulticlassAccuracy(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "    f1_metric = MulticlassF1Score(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "    precision_metric = MulticlassPrecision(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "    recall_metric = MulticlassRecall(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "\n",
    "    total_seg_loss, total_cls_loss = 0, 0\n",
    "    inference_times, all_dice_scores = [], []\n",
    "    loader_tqdm = tqdm(loader, desc=\"Evaluating\")\n",
    "    num_batches_to_run = 2 if config.TEST_IMPLEMENTATION else len(loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, masks, labels) in enumerate(loader_tqdm):\n",
    "            if config.TEST_IMPLEMENTATION and i >= 2: break\n",
    "            \n",
    "            imgs, masks, labels = imgs.to(config.DEVICE), masks.to(config.DEVICE), labels.to(config.DEVICE)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            seg_pred, cls_pred = model(imgs)\n",
    "            inference_times.append(time.time() - start_time)\n",
    "\n",
    "            loss_s = seg_criterion(seg_pred, masks)\n",
    "            loss_c = cls_criterion(cls_pred, labels)\n",
    "            total_seg_loss += loss_s.item()\n",
    "            total_cls_loss += loss_c.item()\n",
    "            \n",
    "            loader_tqdm.set_postfix(seg_loss=loss_s.item(), cls_loss=loss_c.item())\n",
    "\n",
    "            # Cập nhật metrics\n",
    "            seg_pred_binary = (seg_pred > 0.5).float()\n",
    "            jaccard.update(seg_pred_binary, masks.int())\n",
    "            all_dice_scores.append(dice_coefficient(masks, seg_pred_binary).item())\n",
    "            \n",
    "            if config.CLASSIFICATION_HEAD == 'capsnet':\n",
    "                cls_pred_indices = cls_pred.argmax(dim=1)\n",
    "            else:\n",
    "                cls_pred_indices = F.softmax(cls_pred, dim=1).argmax(dim=1)\n",
    "            \n",
    "            accuracy_metric.update(cls_pred_indices, labels)\n",
    "            f1_metric.update(cls_pred_indices, labels)\n",
    "            precision_metric.update(cls_pred_indices, labels)\n",
    "            recall_metric.update(cls_pred_indices, labels)\n",
    "    \n",
    "    # Tính toán kết quả cuối cùng\n",
    "    metrics = {\n",
    "        \"seg_loss\": total_seg_loss / num_batches_to_run,\n",
    "        \"cls_loss\": total_cls_loss / num_batches_to_run,\n",
    "        \"iou\": jaccard.compute().item(),\n",
    "        \"dice\": sum(all_dice_scores) / len(all_dice_scores) if all_dice_scores else 0.0,\n",
    "        \"accuracy\": accuracy_metric.compute().item(),\n",
    "        \"f1\": f1_metric.compute().item(),\n",
    "        \"precision\": precision_metric.compute().item(),\n",
    "        \"recall\": recall_metric.compute().item(),\n",
    "        \"inference_time\": sum(inference_times) / len(inference_times) if inference_times else 0.0\n",
    "    }\n",
    "    \n",
    "    # Reset metrics cho lần evaluate tiếp theo\n",
    "    jaccard.reset(); accuracy_metric.reset(); f1_metric.reset(); precision_metric.reset(); recall_metric.reset()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ==============================================================================\n",
    "# PHẦN V-B: CÁC HÀM TRAIN/EVAL CHO MÔ HÌNH SEQUENTIAL\n",
    "# ==============================================================================\n",
    "\n",
    "def train_seg_only(model, loader, optimizer, criterion, epoch):\n",
    "    \"\"\"Hàm train chỉ cho mô hình segmentation.\"\"\"\n",
    "    model.train()\n",
    "    loader_tqdm = tqdm(loader, desc=f\"Epoch {epoch+1} [Train Seg]\")\n",
    "    total_loss = 0\n",
    "    num_batches = 10 if config.TEST_IMPLEMENTATION else len(loader)\n",
    "\n",
    "    for i, (imgs, masks, _) in enumerate(loader_tqdm):\n",
    "        if config.TEST_IMPLEMENTATION and i >= 10: break\n",
    "        imgs, masks = imgs.to(config.DEVICE), masks.to(config.DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        seg_pred = model(imgs)\n",
    "        loss = criterion(seg_pred, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loader_tqdm.set_postfix(loss=loss.item())\n",
    "        \n",
    "    return total_loss / num_batches\n",
    "\n",
    "def evaluate_seg_only(model, loader, criterion):\n",
    "    \"\"\"Hàm đánh giá chỉ cho mô hình segmentation.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, all_dice_scores = 0, []\n",
    "    loader_tqdm = tqdm(loader, desc=\"[Eval Seg]\")\n",
    "    num_batches = 2 if config.TEST_IMPLEMENTATION else len(loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, masks, _) in enumerate(loader_tqdm):\n",
    "            if config.TEST_IMPLEMENTATION and i >= 2: break\n",
    "            imgs, masks = imgs.to(config.DEVICE), masks.to(config.DEVICE)\n",
    "            \n",
    "            seg_pred = model(imgs)\n",
    "            loss = criterion(seg_pred, masks)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            seg_pred_binary = (seg_pred > 0.5).float()\n",
    "            all_dice_scores.append(dice_coefficient(masks, seg_pred_binary).item())\n",
    "            \n",
    "    return total_loss / num_batches, sum(all_dice_scores) / len(all_dice_scores)\n",
    "\n",
    "def train_cls_only(model, loader, optimizer, criterion, epoch):\n",
    "    \"\"\"Hàm train chỉ cho mô hình classification (đầu vào là predicted mask).\"\"\"\n",
    "    model.train()\n",
    "    loader_tqdm = tqdm(loader, desc=f\"Epoch {epoch+1} [Train Cls]\")\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "    num_batches = 10 if config.TEST_IMPLEMENTATION else len(loader)\n",
    "    \n",
    "    for i, (pred_masks, labels) in enumerate(loader_tqdm):\n",
    "        if config.TEST_IMPLEMENTATION and i >= 10: break\n",
    "        pred_masks, labels = pred_masks.to(config.DEVICE), labels.to(config.DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cls_pred = model(pred_masks)\n",
    "        loss = criterion(cls_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        # Tính accuracy đơn giản để theo dõi\n",
    "        preds = cls_pred.argmax(dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        loader_tqdm.set_postfix(loss=loss.item(), acc=total_correct/total_samples)\n",
    "\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def evaluate_cls_only(model, loader, criterion):\n",
    "    \"\"\"Hàm đánh giá chỉ cho mô hình classification.\"\"\"\n",
    "    model.eval()\n",
    "    accuracy_metric = MulticlassAccuracy(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "    f1_metric = MulticlassF1Score(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "    total_loss = 0\n",
    "    num_batches = 2 if config.TEST_IMPLEMENTATION else len(loader)\n",
    "    loader_tqdm = tqdm(loader, desc=\"[Eval Cls]\")\n",
    "    with torch.no_grad():\n",
    "        for i, (pred_masks, labels) in enumerate(loader_tqdm):\n",
    "            if config.TEST_IMPLEMENTATION and i >= 2: break\n",
    "            pred_masks, labels = pred_masks.to(config.DEVICE), labels.to(config.DEVICE)\n",
    "            \n",
    "            cls_pred = model(pred_masks)\n",
    "            loss = criterion(cls_pred, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            cls_pred_indices = cls_pred.argmax(dim=1)\n",
    "            accuracy_metric.update(cls_pred_indices, labels)\n",
    "            f1_metric.update(cls_pred_indices, labels)\n",
    "\n",
    "    metrics = {\n",
    "        \"cls_loss\": total_loss / num_batches,\n",
    "        \"accuracy\": accuracy_metric.compute().item(),\n",
    "        \"f1\": f1_metric.compute().item()\n",
    "    }\n",
    "    accuracy_metric.reset(); f1_metric.reset()\n",
    "    return metrics\n",
    "\n",
    "def evaluate_sequential_pipeline(seg_model, cls_model, loader, seg_criterion):\n",
    "    \"\"\"Đánh giá toàn bộ pipeline sequential.\"\"\"\n",
    "    seg_model.eval()\n",
    "    cls_model.eval()\n",
    "    \n",
    "    # Khởi tạo metrics từ torchmetrics\n",
    "    jaccard = JaccardIndex(task=\"binary\").to(config.DEVICE)\n",
    "    accuracy_metric = MulticlassAccuracy(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "    f1_metric = MulticlassF1Score(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "    precision_metric = MulticlassPrecision(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "    recall_metric = MulticlassRecall(num_classes=config.NUM_CLASSES, average='macro').to(config.DEVICE)\n",
    "\n",
    "    total_seg_loss = 0\n",
    "    inference_times, all_dice_scores = [], []\n",
    "    loader_tqdm = tqdm(loader, desc=\"[Final Eval Sequential]\")\n",
    "    num_batches_to_run = 2 if config.TEST_IMPLEMENTATION else len(loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, masks, labels) in enumerate(loader_tqdm):\n",
    "            if config.TEST_IMPLEMENTATION and i >= 2: break\n",
    "            imgs, masks, labels = imgs.to(config.DEVICE), masks.to(config.DEVICE), labels.to(config.DEVICE)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            # Stage 1: Segmentation\n",
    "            seg_pred = seg_model(imgs)\n",
    "            seg_pred_binary_for_cls = (seg_pred > 0.5).float() \n",
    "            # Stage 2: Classification\n",
    "            cls_pred = cls_model(seg_pred_binary_for_cls) # Đầu vào là predicted mask\n",
    "            inference_times.append(time.time() - start_time)\n",
    "\n",
    "            # --- Tính metrics ---\n",
    "            loss_s = seg_criterion(seg_pred, masks)\n",
    "            total_seg_loss += loss_s.item()\n",
    "            \n",
    "            seg_pred_binary = (seg_pred > 0.5).float()\n",
    "            jaccard.update(seg_pred_binary, masks.int())\n",
    "            all_dice_scores.append(dice_coefficient(masks, seg_pred_binary).item())\n",
    "            \n",
    "            cls_pred_indices = cls_pred.argmax(dim=1)\n",
    "            accuracy_metric.update(cls_pred_indices, labels)\n",
    "            f1_metric.update(cls_pred_indices, labels)\n",
    "            precision_metric.update(cls_pred_indices, labels)\n",
    "            recall_metric.update(cls_pred_indices, labels)\n",
    "\n",
    "    metrics = {\n",
    "        \"seg_loss\": total_seg_loss / num_batches_to_run,\n",
    "        \"cls_loss\": -1, # Không có cls_loss ở đây\n",
    "        \"iou\": jaccard.compute().item(),\n",
    "        \"dice\": sum(all_dice_scores) / len(all_dice_scores) if all_dice_scores else 0.0,\n",
    "        \"accuracy\": accuracy_metric.compute().item(),\n",
    "        \"f1\": f1_metric.compute().item(),\n",
    "        \"precision\": precision_metric.compute().item(),\n",
    "        \"recall\": recall_metric.compute().item(),\n",
    "        \"inference_time\": sum(inference_times) / len(inference_times) if inference_times else 0.0\n",
    "    }\n",
    "    jaccard.reset(); accuracy_metric.reset(); f1_metric.reset(); precision_metric.reset(); recall_metric.reset()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T18:35:49.041532Z",
     "iopub.status.busy": "2025-07-27T18:35:49.041278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# PHẦN VI. MAIN WORKFLOW\n",
    "# =================================================================================\n",
    "\n",
    "def run_multitask_pipeline(config, train_list, test_list, image_transform, run_id):\n",
    "    \"\"\"Quy trình huấn luyện và đánh giá cho mô hình Multitask.\"\"\"\n",
    "    print(f\"\\n===== BẮT ĐẦU QUY TRÌNH MULTITASK (RUN {run_id+1}) =====\")\n",
    "    \n",
    "    # --- Data & Transforms ---\n",
    "    mask_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_joint_transform = Compose([Resize(config.IMG_SIZE), RandomHorizontallyFlip(), RandomVerticallyFlip(), RandomRotate(15)])\n",
    "    test_joint_transform = Compose([Resize(config.IMG_SIZE)])\n",
    "\n",
    "    train_dataset = BUSIDataset(train_list, train_joint_transform, image_transform, mask_transform)\n",
    "    test_dataset = BUSIDataset(test_list, test_joint_transform, image_transform, mask_transform)\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    print(\"Đã tạo DataLoader cho Multitask.\\n\")\n",
    "    \n",
    "    # --- Model, Loss, Optimizer ---\n",
    "    model = UNet_MTL(config).to(config.DEVICE)\n",
    "    seg_criterion = DiceLoss()\n",
    "    cls_criterion = MarginLoss() if config.CLASSIFICATION_HEAD == 'capsnet' else nn.CrossEntropyLoss()\n",
    "    combined_loss_func = UncertaintyWeightedLoss().to(config.DEVICE)\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()) + list(combined_loss_func.parameters()), lr=config.LEARNING_RATE)\n",
    "    \n",
    "    early_stopper = EarlyStopping(patience=config.EARLY_STOPPING_PATIENCE, path=f\"{config.MTL_MODEL_CHECKPOINT_PATH}_run{run_id+1}.pt\")\n",
    "    \n",
    "    # --- Training Loop ---\n",
    "    print(\"===== BẮT ĐẦU HUẤN LUYỆN MULTITASK =====\")\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        if config.TEST_IMPLEMENTATION and epoch >= 15: break\n",
    "        train_loss, _, _ = train_one_epoch(model, train_loader, optimizer, seg_criterion, cls_criterion, combined_loss_func, epoch)\n",
    "        eval_metrics = evaluate(model, test_loader, seg_criterion, cls_criterion, config)\n",
    "        val_avg = (eval_metrics['dice']+eval_metrics['f1'])/2\n",
    "        print(f\"Epoch {epoch+1}/{config.EPOCHS} | Train Loss: {train_loss:.4f} | Val Dice: {eval_metrics['dice']:.4f} | Val F1: {eval_metrics['f1']:.4f}\")\n",
    "\n",
    "        early_stopper(val_avg, model)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Dừng sớm!\")\n",
    "            break\n",
    "\n",
    "    # --- Final Evaluation ---\n",
    "    print(\"\\n===== ĐÁNH GIÁ CUỐI CÙNG (MULTITASK) =====\")\n",
    "    model.load_state_dict(torch.load(early_stopper.path))\n",
    "    final_metrics = evaluate(model, test_loader, seg_criterion, cls_criterion, config)\n",
    "    return final_metrics, model\n",
    "\n",
    "def run_sequential_pipeline(config, train_list, test_list, image_transform, run_id):\n",
    "    \"\"\"Quy trình huấn luyện và đánh giá cho mô hình Sequential.\"\"\"\n",
    "    print(f\"\\n===== BẮT ĐẦU QUY TRÌNH SEQUENTIAL (RUN {run_id+1}) =====\")\n",
    "\n",
    "    # --- Common Data & Transforms ---\n",
    "    mask_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_joint_transform = Compose([Resize(config.IMG_SIZE), RandomHorizontallyFlip(), RandomVerticallyFlip(), RandomRotate(15)])\n",
    "    test_joint_transform = Compose([Resize(config.IMG_SIZE)])\n",
    "\n",
    "    # ===========================================================\n",
    "    # STAGE 1: TRAIN SEGMENTATION MODEL\n",
    "    # ===========================================================\n",
    "    print(\"\\n--- STAGE 1: HUẤN LUYỆN MÔ HÌNH SEGMENTATION ---\")\n",
    "    seg_model = UNet_Segmentation(config).to(config.DEVICE)\n",
    "    seg_criterion = DiceLoss()\n",
    "    optimizer_seg = torch.optim.Adam(seg_model.parameters(), lr=config.LEARNING_RATE)\n",
    "    early_stopper_seg = EarlyStopping(patience=config.EARLY_STOPPING_PATIENCE, path=f\"{config.SEG_MODEL_CHECKPOINT_PATH}_run{run_id+1}.pt\")\n",
    "    \n",
    "    train_dataset_seg = BUSIDataset(train_list, train_joint_transform, image_transform, mask_transform)\n",
    "    test_dataset_seg = BUSIDataset(test_list, test_joint_transform, image_transform, mask_transform)\n",
    "    train_loader_seg = data.DataLoader(train_dataset_seg, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    test_loader_seg = data.DataLoader(test_dataset_seg, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    for epoch in range(int(config.EPOCHS/2)):\n",
    "        if config.TEST_IMPLEMENTATION and epoch >= 15: break\n",
    "        train_loss = train_seg_only(seg_model, train_loader_seg, optimizer_seg, seg_criterion, epoch)\n",
    "        val_loss, val_dice = evaluate_seg_only(seg_model, test_loader_seg, seg_criterion)\n",
    "        print(f\"Epoch {epoch+1} [Seg] | Train Loss: {train_loss:.4f} | Val Dice: {val_dice:.4f}\")\n",
    "        early_stopper_seg(val_dice, seg_model)\n",
    "        if early_stopper_seg.early_stop:\n",
    "            print(\"Dừng sớm Stage 1!\")\n",
    "            break\n",
    "            \n",
    "    # Load best segmentation model\n",
    "    best_seg_model = UNet_Segmentation(config).to(config.DEVICE)\n",
    "    best_seg_model.load_state_dict(torch.load(early_stopper_seg.path))\n",
    "    best_seg_model.eval()\n",
    "    print(\"Đã tải mô hình segmentation tốt nhất.\")\n",
    "\n",
    "    # ===========================================================\n",
    "    # STAGE 2: TRAIN CLASSIFICATION MODEL\n",
    "    # ===========================================================\n",
    "    print(\"\\n--- STAGE 2: HUẤN LUYỆN MÔ HÌNH CLASSIFICATION ---\")\n",
    "    cls_model = ClassificationModel(config).to(config.DEVICE)\n",
    "    cls_criterion = MarginLoss() if config.CLASSIFICATION_HEAD == 'capsnet' else nn.CrossEntropyLoss()\n",
    "    optimizer_cls = torch.optim.Adam(cls_model.parameters(), lr=config.LEARNING_RATE)\n",
    "    early_stopper_cls = EarlyStopping(patience=config.EARLY_STOPPING_PATIENCE, path=f\"{config.CLS_MODEL_CHECKPOINT_PATH}_run{run_id+1}.pt\", mode='max') \n",
    "\n",
    "    # Sử dụng ClassificationSequentialDataset với image_transform đã có\n",
    "    # Class này sẽ tự động đọc ảnh, áp dụng transform và đưa qua seg_model\n",
    "    train_dataset_cls = ClassificationSequentialDataset(train_list, best_seg_model, config.IMG_SIZE, image_transform=image_transform)\n",
    "    test_dataset_cls = ClassificationSequentialDataset(test_list, best_seg_model, config.IMG_SIZE,image_transform=image_transform)\n",
    "    train_loader_cls = data.DataLoader(train_dataset_cls, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    test_loader_cls = data.DataLoader(test_dataset_cls, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    for epoch in range(int(config.EPOCHS/2)):\n",
    "        if config.TEST_IMPLEMENTATION and epoch >= 30: break\n",
    "        train_loss = train_cls_only(cls_model, train_loader_cls, optimizer_cls, cls_criterion, epoch)\n",
    "        eval_metrics_cls = evaluate_cls_only(cls_model, test_loader_cls, cls_criterion)\n",
    "        val_f1 = eval_metrics_cls['f1']\n",
    "        print(f\"Epoch {epoch+1} [Cls] | Train Loss: {train_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
    "        early_stopper_cls(val_f1, cls_model)\n",
    "        if early_stopper_cls.early_stop:\n",
    "            print(\"Dừng sớm Stage 2!\")\n",
    "            break\n",
    "\n",
    "    # Load best classification model\n",
    "    best_cls_model = ClassificationModel(config).to(config.DEVICE)\n",
    "    best_cls_model.load_state_dict(torch.load(early_stopper_cls.path))\n",
    "    best_cls_model.eval()\n",
    "    print(\"Đã tải mô hình classification tốt nhất.\")\n",
    "\n",
    "    # --- Final Evaluation ---\n",
    "    print(\"\\n===== ĐÁNH GIÁ CUỐI CÙNG (SEQUENTIAL) =====\")\n",
    "    # Dùng test_loader_seg vì nó chứa (ảnh gốc, mask gốc, label)\n",
    "    final_metrics = evaluate_sequential_pipeline(best_seg_model, best_cls_model, test_loader_seg, seg_criterion)\n",
    "    return final_metrics, (best_seg_model, best_cls_model)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "    all_runs_metrics = []\n",
    "    \n",
    "    for run in range(config.NUM_RUNS):\n",
    "        print(f\"\\n{'='*30} BẮT ĐẦU LẦN CHẠY {run+1}/{config.NUM_RUNS} {'='*30}\")\n",
    "        current_seed = config.SEED + run\n",
    "        set_seed(current_seed)\n",
    "        print(f\"Cố định seed cho lần chạy này là: {current_seed}\")\n",
    "\n",
    "        print(\"\\n===== CẤU HÌNH THỬ NGHIỆM =====\")\n",
    "        print(f\"Device: {config.DEVICE}\")\n",
    "        print(f\"Model Type: {config.MODEL_TYPE}\")\n",
    "        print(f\"Backbone: {config.BACKBONE}\")\n",
    "        print(f\"Sử dụng Deformable Conv: {config.USE_Deform}\")\n",
    "        print(f\"Nhánh phân loại: {config.CLASSIFICATION_HEAD}\")\n",
    "        print(f\"Chế độ Debug: {config.TEST_IMPLEMENTATION}\\n\")\n",
    "\n",
    "        # --- Bước 1: Load và chia dataset ---\n",
    "        full_dataset_list = make_dataset(config.DATASET_PATH, config.OUTPUT_MASK_DIR)\n",
    "        labels_for_split = [item[2] for item in full_dataset_list]\n",
    "        train_list, test_list = train_test_split(\n",
    "            full_dataset_list, test_size=config.TEST_RATIO, random_state=config.SEED, stratify=labels_for_split\n",
    "        )\n",
    "        print(f\"Dataset được chia thành: {len(train_list)} mẫu train và {len(test_list)} mẫu test.\")\n",
    "\n",
    "        # --- Bước 2: Tính Mean/Std và tạo Transform chung ---\n",
    "        # Chỉ cần transform cơ bản để tính toán\n",
    "        temp_transform = Compose([Resize(config.IMG_SIZE)])\n",
    "        temp_dataset = BUSIDataset(train_list, joint_transform=temp_transform, image_transform=transforms.ToTensor())\n",
    "        mean, std = calculate_mean_std(temp_dataset)\n",
    "        \n",
    "        image_final_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "        print(f\"Calculated Mean: {mean}\\nCalculated Std: {std}\\n\")\n",
    "        \n",
    "        # --- Bước 3: Chạy pipeline tương ứng ---\n",
    "        if config.MODEL_TYPE == 'multitask':\n",
    "            final_metrics, model = run_multitask_pipeline(config, train_list, test_list, image_final_transform, run)\n",
    "        elif config.MODEL_TYPE == 'sequential':\n",
    "            final_metrics, models = run_sequential_pipeline(config, train_list, test_list, image_final_transform, run)\n",
    "            model_seg = models[0] # Lấy seg_model để tính FLOPs/params\n",
    "            model_cls = models[1] # Lấy cls_model để tính FLOPs/params\n",
    "        else:\n",
    "            raise ValueError(f\"Model type '{config.MODEL_TYPE}' không được hỗ trợ.\")\n",
    "\n",
    "        all_runs_metrics.append(final_metrics)\n",
    "\n",
    "        # --- Bước 4: Tính FLOPs và Params (chỉ lần đầu) ---\n",
    "        if run == 0:\n",
    "            if config.MODEL_TYPE=='multitask':\n",
    "                dummy_input = torch.randn(1, 3, config.IMG_SIZE, config.IMG_SIZE).to(config.DEVICE)           \n",
    "                flops, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "                print(f\"\\n===== Hiệu suất tính toán ({'MTL'}) =====\")\n",
    "                print(f\"Parameters: {params / 1e6:.2f}M\")\n",
    "                print(f\"FLOPs: {flops / 1e9:.2f}G\\n\")\n",
    "            else:\n",
    "                # Dummy input cho model segmentation (3 kênh)\n",
    "                dummy_input_seg = torch.randn(1, 3, config.IMG_SIZE, config.IMG_SIZE).to(config.DEVICE)\n",
    "                flops_seg, params_seg = profile(model_seg, inputs=(dummy_input_seg,), verbose=False)\n",
    "            \n",
    "                # Dummy input cho model classification (1 kênh)\n",
    "                dummy_input_cls = torch.randn(1, 1, config.IMG_SIZE, config.IMG_SIZE).to(config.DEVICE)\n",
    "                flops_cls, params_cls = profile(model_cls, inputs=(dummy_input_cls,), verbose=False)\n",
    "            \n",
    "                # Tổng hợp lại\n",
    "                flops = flops_seg + flops_cls\n",
    "                params = params_seg + params_cls\n",
    "                print(f\"===== Hiệu suất tính toán (Sequential) =====\")\n",
    "                print(f\"Parameters: {params / 1e6:.2f}M\")\n",
    "                print(f\"FLOPs: {flops / 1e9:.2f}G\\n\")\n",
    "            \n",
    "        # --- Bước 5: In kết quả lần chạy hiện tại ---\n",
    "        print(f\"--- Kết quả lần chạy {run+1} ---\")\n",
    "        for key, value in final_metrics.items():\n",
    "            print(f\"{key.capitalize():<15}: {value:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    # --- Bước 6: Tổng hợp và báo cáo kết quả cuối cùng ---\n",
    "    if all_runs_metrics:\n",
    "        print(f\"\\n\\n{'='*30} KẾT QUẢ TỔNG HỢP SAU {config.NUM_RUNS} LẦN CHẠY {'='*30}\")\n",
    "        results_df = pd.DataFrame(all_runs_metrics)\n",
    "        mean_metrics = results_df.mean()\n",
    "        std_metrics = results_df.std()\n",
    "\n",
    "        print(f\"Cấu hình: Model '{config.MODEL_TYPE}', Backbone '{config.BACKBONE}', Phân loại '{config.CLASSIFICATION_HEAD}', Deformable: {config.USE_Deform}\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"{'Metric':<20} | {'Mean':>15} | {'Std Dev':>15}\")\n",
    "        print(\"-\" * 60)\n",
    "        for metric_name in mean_metrics.index:\n",
    "            mean_val = mean_metrics[metric_name]\n",
    "            std_val = std_metrics[metric_name]\n",
    "            print(f\"{metric_name.capitalize():<20} | {mean_val:>15.4f} | {std_val:>15.4f}\")\n",
    "        print(\"-\" * 60)\n",
    "        results_df.to_csv('output.csv', index=False)\n",
    "        print(\"Đã lưu kết quả vào output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7492937,
     "sourceId": 11918761,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
